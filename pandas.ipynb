{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5e11e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import csv\n",
    "import ast\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6190012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4137145",
   "metadata": {},
   "outputs": [],
   "source": [
    "allRecipes = pd.read_csv('CSE158-assignment_2/RAW_recipes.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bcaf894",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = pd.read_csv('CSE158-assignment_2/RAW_interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "548ce8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(allRecipes, interactions, how='outer', left_on='id', right_on='recipe_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4214e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['user_recipe_pair'] = dataset['user_id'].astype(str) + ',' + dataset['recipe_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd0e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['review'] = dataset['review'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba020628",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.3, shuffle=True)\n",
    "# train, valid = train_test_split(train, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa3cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c521428",
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDs, itemIDs = {},{}\n",
    "\n",
    "for user, item in zip(dataset['user_id'], dataset['recipe_id']):\n",
    "    if not user in userIDs: userIDs[user] = len(userIDs)\n",
    "    if not item in itemIDs: itemIDs[item] = len(itemIDs)\n",
    "\n",
    "nUsers, nItems = len(userIDs), len(itemIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd3f5c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scipy.sparse.lil_matrix((dataset.shape[0], nUsers + nItems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f365c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(dataset['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c677b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dataset.shape[0]):\n",
    "    user = userIDs[dataset.loc[i]['user_id']]\n",
    "    item = itemIDs[dataset.loc[i]['recipe_id']]\n",
    "    X[i, user] = 1 # One-hot encoding of user\n",
    "    X[i, nUsers + item] = 1 # One-hot encoding of item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e312df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastFM import als\n",
    "# fm = als.FMRegression(n_iter=1000, init_stdev=0.1, rank=5, l2_reg_w=0.1, l2_reg_V=0.5)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "# fm.fit(X_train, y_train)\n",
    "# y_pred = fm.predict(X_test)\n",
    "# MSE(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bf7da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "itemNames = {}\n",
    "ratingDict = {}\n",
    "\n",
    "[usersPerItem[item].add(user) for user, item in zip(train['user_id'], train['recipe_id'])]\n",
    "[itemsPerUser[user].add(item) for user, item in zip(train['user_id'], train['recipe_id'])]\n",
    "[reviewsPerUser[int(user_item.split(',')[0])].append((rating, int(user_item.split(',')[1]))) for user_item, rating in zip(train['user_recipe_pair'], train['rating'])]\n",
    "#[reviewsPerUser[dataset.iloc[i]['user_id']].append(dataset.iloc[i]) for i in range(dataset.shape[0])]#user, rating in zip(dataset['user_id'], dataset['rating'])]\n",
    "[reviewsPerItem[int(user_item.split(',')[1])].append((rating, int(user_item.split(',')[0]))) for user_item, rating in zip(train['user_recipe_pair'], train['rating'])]\n",
    "#[reviewsPerItem[item].append(rating) for item, rating in zip(dataset['recipe_id'], dataset['rating'])]\n",
    "ratingDict = {(int(user_item.split(',')[0]), int(user_item.split(',')[1])): rating for user_item, rating in zip(train['user_recipe_pair'], train['rating'])}\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "593e7627",
   "metadata": {},
   "outputs": [],
   "source": [
    "userAverages = {}\n",
    "itemAverages = {}\n",
    "ratingMean = []\n",
    "\n",
    "for u in itemsPerUser:\n",
    "    rs = [ratingDict[(u,i)] for i in itemsPerUser[u]]\n",
    "    userAverages[u] = sum(rs) / len(rs)\n",
    "    \n",
    "for i in usersPerItem:\n",
    "    rs = [ratingDict[(u,i)] for u in usersPerItem[i]]\n",
    "    itemAverages[i] = sum(rs) / len(rs)\n",
    "    \n",
    "ratingMean = list(train['rating'])\n",
    "    \n",
    "ratingMean = sum(ratingMean) / len(ratingMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c743f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alwaysPredictMean_valid = [ratingMean] * valid.shape[0]\n",
    "# alwaysPredictFive_valid = [5] * valid.shape[0]\n",
    "\n",
    "alwaysPredictMean_test = [ratingMean] * test.shape[0]\n",
    "alwaysPredictFive_test = [5] * test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "738d75f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, ypred):\n",
    "    diffs = [(a-b)**2 for (a,b) in zip(y,ypred)]\n",
    "    return sum(diffs) / len(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a6881d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bc20ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRating(user, item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d[1]\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d[0] - itemAverages[i2])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        return ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b83278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_preds = [predictRating(user, recipe) for user, recipe in zip(valid['user_id'], valid['recipe_id'])]\n",
    "test_preds = [predictRating(user, recipe) for user, recipe in zip(test['user_id'], test['recipe_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a3ee28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = list(train['rating'])\n",
    "# valid_labels = list(valid['rating'])\n",
    "test_labels = list(test['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d254a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_mean_valid = MSE(alwaysPredictMean_valid, valid_labels)\n",
    "# mse_five_valid = MSE(alwaysPredictFive_valid, valid_labels)\n",
    "# mse_valid = MSE(valid_preds, valid_labels)\n",
    "\n",
    "mse_mean_test = MSE(alwaysPredictMean_test, test_labels)\n",
    "mse_five_test = MSE(alwaysPredictFive_test, test_labels)\n",
    "mse_test = MSE(test_preds, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6c96ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_mean_valid, mse_five_valid, mse_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b01c498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.598506386225117, 1.9444704469387215, 1.7458351615777992)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_mean_test, mse_five_test, mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e54a6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round_valid = [round(i) for i in valid_preds]\n",
    "# round_test = [round(i) for i in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4409599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_round_valid = MSE(round_valid, valid_labels)\n",
    "# mse_round_test = MSE(round_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5857678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_round_valid, mse_round_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a50120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ingredients'] = dataset['ingredients'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd234994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# ing_counts = Counter([ing for ing_lst in dataset['ingredients'] for ing in ing_lst])\n",
    "# ing_counts = ing_counts.most_common(1000)\n",
    "# ings = [ing for ing, count in ing_counts]\n",
    "# ingsIdx = dict(zip(ings, range(len(ings))))\n",
    "# ings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "959f55d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviewtext_wordCount = defaultdict(int)\n",
    "# punctuation = set(string.punctuation)\n",
    "# for d in train['review']:\n",
    "#     r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "#     for w in r.split():\n",
    "#         reviewtext_wordCount[w] += 1\n",
    "\n",
    "# reviewtext_counts = [(reviewtext_wordCount[w], w) for w in reviewtext_wordCount]\n",
    "# reviewtext_counts.sort(reverse=True)\n",
    "\n",
    "# reviewtext_words = [x[1] for x in reviewtext_counts[:1000]]\n",
    "\n",
    "# reviewtext_wordId = dict(zip(reviewtext_words, range(len(reviewtext_words))))\n",
    "# reviewtext_wordSet = set(reviewtext_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5effe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in train['review']:\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    ws = r.split()\n",
    "    ws2 = [' '.join(x) for x in list(zip(ws[:-1],ws[1:]))]\n",
    "    for w in ws + ws2:\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort(reverse=True)\n",
    "\n",
    "mostCommon = [x[1] for x in counts][:1000]\n",
    "\n",
    "wordId = dict(zip(mostCommon, range(len(mostCommon))))\n",
    "wordSet = set(mostCommon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e084e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_review(datum):\n",
    "    feat = [0]*len(wordSet)\n",
    "    r = ''.join([c for c in datum.lower() if not c in punctuation])\n",
    "    ws = r.split()\n",
    "    ws2 = [' '.join(x) for x in list(zip(ws[:-1],ws[1:]))]\n",
    "    for w in ws + ws2:\n",
    "        if w in wordSet:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d681c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(d):\n",
    "    feat = []\n",
    "    feat.append(predictRating(d['user_id'], d['recipe_id']))\n",
    "    if d['review'] != None:\n",
    "        feat.append(len(d['review']))\n",
    "    else:\n",
    "        feat.append(0)\n",
    "    feat += bow_review(d['review'])\n",
    "#     for ing in d['ingredients']:\n",
    "#         if ing in ingsIdx:\n",
    "#             feat[ingsIdx[ing]] += 1\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05eef8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [feature(train.iloc[i]) for i in range(train.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de95616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_valid = [feature(valid.iloc[i]) for i in range(valid.shape[0])]\n",
    "X_test = [feature(test.iloc[i]) for i in range(test.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a559282",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_log = linear_model.LogisticRegression(class_weight='balanced')\n",
    "mod_log.fit(X_train, train_labels)\n",
    "# preds_valid = mod_log.predict(X_valid)\n",
    "preds_test = mod_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3de1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = mod_log.predict(X_train)\n",
    "mse_log_train = MSE(preds_train, train_labels)\n",
    "mse_log_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be5a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_log_valid = MSE(preds_valid, valid_labels)\n",
    "mse_log_test = MSE(preds_test, test_labels)\n",
    "mse_log_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f251043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_log_valid, mse_log_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8755c61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
